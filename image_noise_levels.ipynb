{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1b2d21-bfdb-4bec-a046-fe34e0dcbef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, sys, os, copy\n",
    "import sigpy as sp\n",
    "from scipy import signal\n",
    "from scipy.stats import norm\n",
    "import h5py\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm as tqdm_base\n",
    "\n",
    "from ncsnv2.models import get_sigmas\n",
    "from parameters import pairwise_dist\n",
    "from parameters import step_size\n",
    "from dotmap import DotMap\n",
    "\n",
    "from tqdm import tqdm as tqdm_base\n",
    "def tqdm(*args, **kwargs):\n",
    "    if hasattr(tqdm_base, '_instances'):\n",
    "        for instance in list(tqdm_base._instances):\n",
    "            tqdm_base._decr_instances(instance)\n",
    "    return tqdm_base(*args, **kwargs)\n",
    "\n",
    "def sigma_rate(tqdm, shape):\n",
    "    # Apply Song's Technique 2\n",
    "    candidate_gamma = np.logspace(np.log10(0.9), np.log10(0.99999), 1000)\n",
    "    gamma_criterion = np.zeros((len(candidate_gamma)))\n",
    "    dataset_shape = np.prod(shape)\n",
    "\n",
    "    for idx, gamma in enumerate(candidate_gamma):\n",
    "        gamma_criterion[idx] = \\\n",
    "            norm.cdf(np.sqrt(2 * dataset_shape) * (gamma - 1) + 3*gamma) - \\\n",
    "            norm.cdf(np.sqrt(2 * dataset_shape) * (gamma - 1) - 3*gamma)\n",
    "    \n",
    "    best_idx = np.argmin(np.abs(gamma_criterion - 0.5))\n",
    "    return candidate_gamma[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2085d779-fc0f-46a5-bf56-a2cb8fd9424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(x, vmax=None):\n",
    "    x = x[0] + 1j*x[1]\n",
    "    x = np.array(x.cpu(), dtype=np.complex64)\n",
    "    if vmax==None:\n",
    "      plt.imshow(np.abs(x), cmap='gray')\n",
    "    else:\n",
    "      plt.imshow(np.abs(x), cmap='gray',vmax=vmax)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel('doppler')\n",
    "    plt.ylabel('range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afaaead-7258-4c25-bec3-a81ba714167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/csiNAS2/slow/mridata/skm_tea2/qdess/v1-release/files_recon_calib-24/'\n",
    "# file_paths = [path+f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "# data = []\n",
    "\n",
    "# for file in tqdm(file_paths):\n",
    "#     with h5py.File(file, 'r') as F:\n",
    "#         if F.keys():\n",
    "#             target = np.squeeze(np.array(F['target'])[:, :, 70:135].transpose(-1, -3, -2, 0, 1))\n",
    "#             for image in target:\n",
    "#                 data.append(image)\n",
    "\n",
    "# data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac88fb6-ddf4-4f14-985d-5454fa19b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = sys.path[0] + '/data/train-val-data/'\n",
    "# path = path + 'train' + '-' + 'experiment-' + '1' + '.txt'\n",
    "# filenames = np.loadtxt(path, dtype='str')\n",
    "# data = []\n",
    "\n",
    "# # ~850  files\n",
    "# for ii in range(len(filenames)):\n",
    "#     with np.load(filenames[ii], allow_pickle=True) as f:\n",
    "#         data.append(f['data'])\n",
    "\n",
    "# reshaped_data = np.array(data, dtype=np.complex64).transpose(0, 3, 1, 2)\n",
    "# reshaped_data = np.reshape(reshaped_data, (-1, reshaped_data.shape[-2], reshaped_data.shape[-1]))\n",
    "# channels = reshaped_data.copy()\n",
    "\n",
    "# masks = []\n",
    "# thr = 0.3\n",
    "# for i in range(len(channels)):\n",
    "#     z = np.max(np.abs(channels[i]))\n",
    "#     mask = np.abs(channels[i]) > thr * z\n",
    "#     masks.append(mask)\n",
    "#     channels[i] = channels[i] * mask\n",
    "\n",
    "# reshaped_data = np.stack((np.real(reshaped_data), np.imag(reshaped_data)), axis=1)\n",
    "# channels = np.stack((np.real(channels), np.imag(channels)), axis=1)\n",
    "# masks = np.stack((np.real(masks), np.imag(masks)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab86e1b-69bc-426b-bcb5-9a23177a4687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = []\n",
    "\n",
    "# for i in range(0, 10000):\n",
    "#     x0 = np.zeros((512*512), dtype=complex)\n",
    "#     Npoints = np.random.randint(1,10)\n",
    "#     idx = np.random.randint(512*512, size=Npoints)\n",
    "\n",
    "#     x0[idx] = np.random.randn(*idx.shape) + 1j * np.random.randn(*idx.shape)\n",
    "\n",
    "#     x0 = x0.reshape((512, 512))\n",
    "#     N = 2\n",
    "#     filt = np.outer(np.hamming(N), np.hamming(N))\n",
    "#     x0 = signal.convolve(x0, filt, mode='same')\n",
    "#     # y0 = sp.fft(x0, axes=(-1,-2))\n",
    "#     x0 = x0 / np.max(np.abs(x0))\n",
    "#     X.append(x0)\n",
    "\n",
    "# torch.save({'X': X}, 'data/mri-data/skm-tea.pt')\n",
    "\n",
    "# channels = torch.load(sys.path[0] + '/data/mri-data/skm-tea-128.pt')['X']\n",
    "# channels = np.stack((np.real(channels), np.imag(channels)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592ca034-17a1-4781-a0c3-5e4f57363905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/csiNAS/sidharth/T2_shuffling_data/checked_data'\n",
    "# file_paths = [path + '/' + f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "# channels = np.zeros((4800, 240, 240), dtype=np.complex64)\n",
    "\n",
    "# i = 0\n",
    "# for file in tqdm(file_paths):\n",
    "#     X = torch.load(file)['final_images']\n",
    "#     for image in X:\n",
    "#         channels[i] = image\n",
    "#         i += 1\n",
    "\n",
    "channels = torch.load(sys.path[0] + '/data/mri-data/knee-tea2.pt')['X']\n",
    "channels = np.stack((np.real(channels), np.imag(channels)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b834ad66-4453-4366-92dd-cce057e6d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/asad/score-based-channels/data/marius-data/'\n",
    "# filenames = [path + f for f in os.listdir(path)]\n",
    "# channels  = []\n",
    "\n",
    "# contents = hdf5storage.loadmat(filenames[4])\n",
    "# channel = np.asarray(contents['output_h'], dtype=np.complex64)\n",
    "\n",
    "# channels.append(channel[:, 0])\n",
    "\n",
    "# # Convert to array\n",
    "# channels = np.asarray(channels)\n",
    "# channels = np.reshape(channels, (-1, channels.shape[-2], channels.shape[-1]))\n",
    "\n",
    "# channels = channels / np.max(np.abs(channels), axis=0)\n",
    "# channels = np.stack((np.real(channels), np.imag(channels)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05fe199c-3651-42c4-9675-1ac76d0c5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DotMap()\n",
    "config.model.num_classes = 2311\n",
    "config.model.sigma_dist = 'geometric'\n",
    "config.device = 'cuda:0'\n",
    "\n",
    "config.model.sigma_begin = np.loadtxt(sys.path[0] + '/parameters/knee-mri_max_pairwise_dist.txt')\n",
    "\n",
    "# config.model.sigma_rate = sigma_rate(tqdm, channels[0].shape)\n",
    "config.model.sigma_rate = 0.9954\n",
    "\n",
    "config.model.sigma_end  = config.model.sigma_begin * config.model.sigma_rate ** (config.model.num_classes - 1)\n",
    "config.model.step_size = step_size(config)\n",
    "\n",
    "sigmas = get_sigmas(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c23baac-c7de-4a8e-a2f2-3fe6cb7bcae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256.06842041015625\n",
      "0.9954\n",
      "0.006065912270894371\n"
     ]
    }
   ],
   "source": [
    "print(config.model.sigma_begin)\n",
    "print(config.model.sigma_rate)\n",
    "print(config.model.sigma_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c0ca4f-17e7-4074-b40a-c3db342c39d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,8))\n",
    "# plt.axis('off')\n",
    "# plt.title('Original Image')\n",
    "# display(torch.tensor((channels[200])))\n",
    "\n",
    "# plt.figure(figsize=(8,8))\n",
    "# plt.title('Mask')\n",
    "# display(torch.tensor(masks[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ddb926a-e42e-4a91-bcfe-541079632583",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    samples = torch.tensor(channels[i]).cuda()\n",
    "    all_labels = torch.tensor([x for x in range(0, len(sigmas), 200)])\n",
    "\n",
    "    perturbed_images = {'original': [],\n",
    "                        'noise_level': [],\n",
    "                        'noise': [],\n",
    "                        'perturbed': []}\n",
    "\n",
    "    for labels in all_labels:\n",
    "        used_sigmas = sigmas[labels].view(([1] * len(samples.shape[0:]))) \n",
    "        noise = torch.randn_like(samples) * used_sigmas\n",
    "        perturbed_samples = samples + noise\n",
    "\n",
    "        perturbed_images['original'] = samples\n",
    "        perturbed_images['noise_level'].append(float(used_sigmas))\n",
    "        perturbed_images['noise'].append(noise)\n",
    "        perturbed_images['perturbed'].append(perturbed_samples)\n",
    "\n",
    "    images.append(perturbed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "080c5d38-478a-4c0b-aced-be1016acbe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = images[9]\n",
    "\n",
    "# for i in range(len(sample['noise_level'])):\n",
    "#     plt.subplots(1, 3, figsize=(16, 6))\n",
    "#     plt.subplot(1,3,1)\n",
    "#     plt.title('original')\n",
    "#     display(sample['original'])\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.subplot(1,3,2)\n",
    "#     plt.title('noise: ' + str(sample['noise_level'][i]))\n",
    "#     display(sample['noise'][i])\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.subplot(1,3,3)\n",
    "#     plt.title('image + noise')\n",
    "#     display(sample['perturbed'][i])\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a8fb1ef-3747-4333-8cb3-5d92cf60ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 6))\n",
    "# # display(torch.tensor(sp.ifft(np.array(sample['original'].cpu()), axes=(-1,-2))))\n",
    "# display(sample['original'])\n",
    "\n",
    "# plt.figure(figsize=(16, 6))\n",
    "# # display(torch.tensor(sp.ifft(np.array(sample['perturbed'][-1].cpu()), axes=(-1,-2))))\n",
    "# display(sample['perturbed'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a05fe-88f3-48c3-b7a8-8326eefbf73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = sys.path[0] + '/data/noisy-images/range_doppler_th0.3-noisy_samples.pt'\n",
    "# torch.save({'images': images}, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-GPU",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
